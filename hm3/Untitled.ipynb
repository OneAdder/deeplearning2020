{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import youtokentome as yttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = list()\n",
    "\n",
    "with open('qa_data.jsonl') as file_object:\n",
    "    for line in file_object:\n",
    "        qa_data.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "questin_answer_data = []\n",
    "for question_answer in qa_data:\n",
    "    questin_answer_data.append(question_answer['question'])\n",
    "    deque(map(questin_answer_data.append, question_answer['responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['долго ли идут деньги с яндексденег на карту visa?',\n",
       " 'нет. прорыв 35 ;)',\n",
       " 'можно ли зарегистрировать авто в другом регионе',\n",
       " 'можно на родственника из того региона.. .  а потом ездить по доверке',\n",
       " 'что делать если у меня очень тонкие ногти а хочется их отрастить?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questin_answer_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('for_bpe.txt', 'w') as f:\n",
    "    f.write('\\n'.join(questin_answer_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del questin_answer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "долго ли идут деньги с яндексденег на карту visa?\r\n",
      "нет. прорыв 35 ;)\r\n",
      "можно ли зарегистрировать авто в другом регионе\r\n",
      "можно на родственника из того региона.. .  а потом ездить по доверке\r\n",
      "что делать если у меня очень тонкие ногти а хочется их отрастить?\r\n",
      "витамины и умная эмаль (каждый день)\r\n",
      "ванночки с морской солью. с вечера мажь ногти сверху йодом. не бойся, до утра все впитается.\r\n",
      "умная эмаль, витамины, йод, и поменьше крась лаком \r\n",
      "лаки фирмы trind производство usa + кальций\r\n",
      "в чем отличие медитации от йоги?\r\n"
     ]
    }
   ],
   "source": [
    "!head for_bpe.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30_000\n",
    "MODEL_PATH = 'pretrained_bpe_lm.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<youtokentome.youtokentome.BPE at 0x7f4ee1aba748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yttm.BPE.train(data='for_bpe.txt', vocab_size=VOCAB_SIZE, model=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(model=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for qa in qa_data:\n",
    "    for answer in qa['responses']:\n",
    "        questions.append(qa['question'])\n",
    "        answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del qa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30341/30341 [01:07<00:00, 447.11it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "tokenized_questions = []\n",
    "\n",
    "for i_batch in tqdm(range(math.ceil(len(questions) / batch_size))):\n",
    "    tokenized_questions.extend(\n",
    "        tokenizer.encode(\n",
    "            list(questions[i_batch*batch_size:(i_batch+1)*batch_size]),\n",
    "            bos=True, eos=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как сложно без gc\n",
    "del questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30341/30341 [01:07<00:00, 450.82it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_answers = []\n",
    "\n",
    "for i_batch in tqdm(range(math.ceil(len(answers) / batch_size))):\n",
    "    tokenized_answers.extend(\n",
    "        tokenizer.encode(\n",
    "            list(answers[i_batch*batch_size:(i_batch+1)*batch_size]),\n",
    "            bos=True, eos=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del answers\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# у меня не хватает памяти, лучше сохраниться\n",
    "import pickle\n",
    "\n",
    "with open('questions', 'wb') as f:\n",
    "    pickle.dump(tokenized_questions, f)\n",
    "\n",
    "with open('answers', 'wb') as f:\n",
    "    pickle.dump(tokenized_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_questions\n",
    "del tokenized_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем брать одну десятую датасета, иначе памяти не хватит\n",
    "with open('questions', 'rb') as f:\n",
    "    questions = pickle.load(f)\n",
    "questions = questions[:int(len(questions)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers', 'rb') as f:\n",
    "    answers = pickle.load(f)\n",
    "answers = answers[:int(len(answers)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776713 776713\n"
     ]
    }
   ],
   "source": [
    "print(len(questions), len(answers))\n",
    "assert len(questions) == len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          14961        3574        8289         306        3097       10758\r\n",
      "Swap:         16134        1232       14902\r\n"
     ]
    }
   ],
   "source": [
    "# найс, у нас занято всего 3 Гб\n",
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceBucketingData(torch.utils.data.Dataset):\n",
    "    \"\"\"по сути то же, что в условии, только другие сиквенсы\"\"\"\n",
    "    def __init__(self, questions, answers, max_len, pad_index, eos_index):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        if len(questions) != len(answers):\n",
    "            raise ValueError('Вопросы и ответы должны быть одной длины')\n",
    "        self.max_len = max_len\n",
    "        self.pad_index = pad_index\n",
    "        self.eos_index = eos_index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def prepare_sample(self, sequence_q, sequence_a, max_len):\n",
    "        sequence_q = sequence_q[:max_len]\n",
    "        sequence_a = sequence_a[:max_len]\n",
    "        x = sequence_q\n",
    "        y = secuence_a\n",
    "        pads = [self.pad_index] * (max_len - len(x))\n",
    "        x += pads\n",
    "        y += pads\n",
    "        return x, y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_q = self.questions[index]\n",
    "        batch_a = self.answers[index]\n",
    "        max_len = min([\n",
    "            self.max_len,\n",
    "            max(map(len, batch_q)),\n",
    "            max(map(len, batch_a)),\n",
    "        ])\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for sample_q, sample_a in zip(batch_q, batch_a):\n",
    "            x, y = self.prepare_sample(sample_q, sample_a, max_len)\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "        batch_x = torch.tensor(batch_x).long().to(DEVICE)\n",
    "        batch_y = torch.tensor(batch_y).long().to(DEVICE)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
