{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imports():\n",
    "    global math, np, pd, random, json, torch, Dataset, DataLoader, tqdm, plt, yttm\n",
    "    \n",
    "    import math\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    import random\n",
    "    import json\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    import youtokentome as yttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = list()\n",
    "\n",
    "with open('qa_data.jsonl') as file_object:\n",
    "    for line in file_object:\n",
    "        qa_data.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "questin_answer_data = []\n",
    "for question_answer in qa_data:\n",
    "    questin_answer_data.append(question_answer['question'])\n",
    "    deque(map(questin_answer_data.append, question_answer['responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['долго ли идут деньги с яндексденег на карту visa?',\n",
       " 'нет. прорыв 35 ;)',\n",
       " 'можно ли зарегистрировать авто в другом регионе',\n",
       " 'можно на родственника из того региона.. .  а потом ездить по доверке',\n",
       " 'что делать если у меня очень тонкие ногти а хочется их отрастить?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questin_answer_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('for_bpe.txt', 'w') as f:\n",
    "    f.write('\\n'.join(questin_answer_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del questin_answer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "долго ли идут деньги с яндексденег на карту visa?\r\n",
      "нет. прорыв 35 ;)\r\n",
      "можно ли зарегистрировать авто в другом регионе\r\n",
      "можно на родственника из того региона.. .  а потом ездить по доверке\r\n",
      "что делать если у меня очень тонкие ногти а хочется их отрастить?\r\n",
      "витамины и умная эмаль (каждый день)\r\n",
      "ванночки с морской солью. с вечера мажь ногти сверху йодом. не бойся, до утра все впитается.\r\n",
      "умная эмаль, витамины, йод, и поменьше крась лаком \r\n",
      "лаки фирмы trind производство usa + кальций\r\n",
      "в чем отличие медитации от йоги?\r\n"
     ]
    }
   ],
   "source": [
    "!head for_bpe.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30_000\n",
    "MODEL_PATH = 'pretrained_bpe_lm.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<youtokentome.youtokentome.BPE at 0x7f6155470f98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yttm.BPE.train(data='for_bpe.txt', vocab_size=VOCAB_SIZE, model=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(model=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for qa in qa_data:\n",
    "    for answer in qa['responses']:\n",
    "        questions.append(qa['question'])\n",
    "        answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del qa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30341/30341 [01:07<00:00, 448.48it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "tokenized_questions = []\n",
    "\n",
    "for i_batch in tqdm(range(math.ceil(len(questions) / batch_size))):\n",
    "    tokenized_questions.extend(\n",
    "        tokenizer.encode(\n",
    "            list(questions[i_batch*batch_size:(i_batch+1)*batch_size]),\n",
    "            bos=True, eos=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как сложно без gc\n",
    "del questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30341/30341 [01:03<00:00, 480.40it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_answers = []\n",
    "\n",
    "for i_batch in tqdm(range(math.ceil(len(answers) / batch_size))):\n",
    "    tokenized_answers.extend(\n",
    "        tokenizer.encode(\n",
    "            list(answers[i_batch*batch_size:(i_batch+1)*batch_size]),\n",
    "            bos=True, eos=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# у меня не хватает памяти, лучше сохраниться\n",
    "import pickle\n",
    "\n",
    "with open('questions', 'wb') as f:\n",
    "    pickle.dump(tokenized_questions, f)\n",
    "\n",
    "with open('answers', 'wb') as f:\n",
    "    pickle.dump(tokenized_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_questions\n",
    "del tokenized_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# будем брать одну десятую датасета, иначе памяти не хватит\n",
    "with open('questions', 'rb') as f:\n",
    "    questions = pickle.load(f)\n",
    "questions = questions[:int(len(questions)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers', 'rb') as f:\n",
    "    answers = pickle.load(f)\n",
    "answers = answers[:int(len(answers)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776713 776713\n"
     ]
    }
   ],
   "source": [
    "print(len(questions), len(answers))\n",
    "assert len(questions) == len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          14961        3096       10458         243        1406       11336\r\n",
      "Swap:         16134        1426       14708\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_INDEX = 0\n",
    "EOS_INDEX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceBucketingData(torch.utils.data.Dataset):\n",
    "    \"\"\"по сути то же, что в условии, только другие сиквенсы\"\"\"\n",
    "    def __init__(self, questions, answers, max_len, pad_index=PAD_INDEX, eos_index=EOS_INDEX):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        if len(questions) != len(answers):\n",
    "            raise ValueError('Вопросы и ответы должны быть одной длины')\n",
    "        self.max_len = max_len\n",
    "        self.pad_index = pad_index\n",
    "        self.eos_index = eos_index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def _prepare_sample(self, sequence_q, sequence_a, max_len):\n",
    "        sequence_q = sequence_q[:max_len]\n",
    "        sequence_a = sequence_a[:max_len]\n",
    "        x = sequence_q\n",
    "        y = sequence_a\n",
    "        pads = [self.pad_index] * (max_len - len(x))\n",
    "        x += pads\n",
    "        y += pads\n",
    "        return x, y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_q = self.questions[index]\n",
    "        batch_a = self.answers[index]\n",
    "        max_len = min([\n",
    "            self.max_len,\n",
    "            max(map(len, batch_q)),\n",
    "            max(map(len, batch_a)),\n",
    "        ])\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for sample_q, sample_a in zip(batch_q, batch_a):\n",
    "            x, y = self._prepare_sample(sample_q, sample_a, max_len)\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "        print(len(batch_x), len(batch_x[0]))\n",
    "        print(len(batch_y), len(batch_y[0]))\n",
    "        batch_x = torch.tensor(batch_x).long().to(DEVICE)\n",
    "        batch_y = torch.tensor(batch_y).long().to(DEVICE)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = sorted(questions, key=len)\n",
    "answers = sorted(answers, key=len)\n",
    "\n",
    "\n",
    "# сделаем батч побольше\n",
    "BATCH_SIZE = 256\n",
    "MAX_LEN = 32\n",
    "\n",
    "batches_q = []\n",
    "batches_a = []\n",
    "\n",
    "for i_batch in range(math.ceil(len(questions) / BATCH_SIZE)):\n",
    "    batches_q.append(questions[i_batch*batch_size:(i_batch+1)*BATCH_SIZE])\n",
    "    batches_a.append(answers[i_batch*batch_size:(i_batch+1)*BATCH_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_start_index = int(len(batches_q) * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = SequenceBucketingData(\n",
    "    questions=batches_q[:-validation_start_index],\n",
    "    answers=batches_a[:-validation_start_index],\n",
    "    max_len=MAX_LEN)\n",
    "test_seq = SequenceBucketingData(\n",
    "    questions=batches_q[-validation_start_index:],\n",
    "    answers=batches_a[-validation_start_index:],\n",
    "    max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_seq, batch_size=BATCH_SIZE)\n",
    "validation_loader = torch.utils.data.DataLoader(test_seq, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# это специальный дропаут для реккуретных сетей\n",
    "# хорошо это объясняется здесь: https://youtu.be/WLaAIYQHHMU?t=1093\n",
    "\n",
    "class SpatialDropout(torch.nn.Dropout2d):\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, padding_idx,\n",
    "                 vocab_size=30_000,\n",
    "                 embedding_dim=128,\n",
    "                 model_dim=128,\n",
    "                 num_layers=2,\n",
    "                 dropout=0.35,\n",
    "                 weight_tying=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size,\n",
    "                                                  embedding_dim=embedding_dim, padding_idx=padding_idx)\n",
    "        \n",
    "        self.embedding_dropout = SpatialDropout(p=dropout)\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size=embedding_dim, hidden_size=model_dim, \n",
    "                                  num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.language_model_head = torch.nn.Linear(in_features=model_dim, out_features=vocab_size, bias=False)\n",
    "        \n",
    "        # как раз здесь задаем, чтобы веса входящего и выходящего слоя эмбеддингов шарились\n",
    "        if weight_tying and embedding_dim == model_dim:\n",
    "            self.language_model_head.weight = self.embedding_layer.weight\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.embedding_layer(x)\n",
    "        \n",
    "        x = self.embedding_dropout(x)\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        x = self.language_model_head(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (embedding_layer): Embedding(30000, 128, padding_idx=0)\n",
       "  (embedding_dropout): SpatialDropout(p=0.35, inplace=False)\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.35)\n",
       "  (language_model_head): Linear(in_features=128, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LanguageModel(padding_idx=PAD_INDEX)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, last_n_losses=500, verbose=True):\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Train')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, y in loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = criterion(pred.view(-1, pred.size(-1)), y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
    "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])))\n",
    "\n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Train:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 27\n",
      "256 28\n",
      "256 29\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 29 at dim 1 (got 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-680b9cbe791e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPAD_INDEX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-108-547ec2217cb3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, last_n_losses, verbose)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-cc9d18f8242c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 29 at dim 1 (got 28)"
     ]
    }
   ],
   "source": [
    "epoch_losses = train(\n",
    "    model, validation_loader,\n",
    "    criterion=torch.nn.CrossEntropyLoss(ignore_index=PAD_INDEX),\n",
    "    optimizer=torch.optim.Adam(params=model.parameters()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
