{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imports():\n",
    "    global math, np, pd, random, json, torch, Dataset, DataLoader, tqdm, plt, yttm\n",
    "    \n",
    "    import math\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    import random\n",
    "    import json\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    import youtokentome as yttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = list()\n",
    "\n",
    "with open('qa_data.jsonl') as file_object:\n",
    "    for line in file_object:\n",
    "        qa_data.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "questin_answer_data = []\n",
    "for question_answer in qa_data:\n",
    "    questin_answer_data.append(question_answer['question'])\n",
    "    deque(map(questin_answer_data.append, question_answer['responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['долго ли идут деньги с яндексденег на карту visa?',\n",
       " 'нет. прорыв 35 ;)',\n",
       " 'можно ли зарегистрировать авто в другом регионе',\n",
       " 'можно на родственника из того региона.. .  а потом ездить по доверке',\n",
       " 'что делать если у меня очень тонкие ногти а хочется их отрастить?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questin_answer_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('for_bpe.txt', 'w') as f:\n",
    "    f.write('\\n'.join(questin_answer_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del questin_answer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "долго ли идут деньги с яндексденег на карту visa?\r\n",
      "нет. прорыв 35 ;)\r\n",
      "можно ли зарегистрировать авто в другом регионе\r\n",
      "можно на родственника из того региона.. .  а потом ездить по доверке\r\n",
      "что делать если у меня очень тонкие ногти а хочется их отрастить?\r\n",
      "витамины и умная эмаль (каждый день)\r\n",
      "ванночки с морской солью. с вечера мажь ногти сверху йодом. не бойся, до утра все впитается.\r\n",
      "умная эмаль, витамины, йод, и поменьше крась лаком \r\n",
      "лаки фирмы trind производство usa + кальций\r\n",
      "в чем отличие медитации от йоги?\r\n"
     ]
    }
   ],
   "source": [
    "!head for_bpe.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30_000\n",
    "MODEL_PATH = 'pretrained_bpe_lm.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<youtokentome.youtokentome.BPE at 0x7f6155470f98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yttm.BPE.train(data='for_bpe.txt', vocab_size=VOCAB_SIZE, model=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(model=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for qa in qa_data:\n",
    "    for answer in qa['responses']:\n",
    "        questions.append(qa['question'])\n",
    "        answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del qa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30341/30341 [01:07<00:00, 448.48it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "tokenized_questions = []\n",
    "\n",
    "for i_batch in tqdm(range(math.ceil(len(questions) / batch_size))):\n",
    "    tokenized_questions.extend(\n",
    "        tokenizer.encode(\n",
    "            list(questions[i_batch*batch_size:(i_batch+1)*batch_size]),\n",
    "            bos=True, eos=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как сложно без gc\n",
    "del questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30341/30341 [01:03<00:00, 480.40it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_answers = []\n",
    "\n",
    "for i_batch in tqdm(range(math.ceil(len(answers) / batch_size))):\n",
    "    tokenized_answers.extend(\n",
    "        tokenizer.encode(\n",
    "            list(answers[i_batch*batch_size:(i_batch+1)*batch_size]),\n",
    "            bos=True, eos=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# у меня не хватает памяти, лучше сохраниться\n",
    "import pickle\n",
    "\n",
    "with open('questions', 'wb') as f:\n",
    "    pickle.dump(tokenized_questions, f)\n",
    "\n",
    "with open('answers', 'wb') as f:\n",
    "    pickle.dump(tokenized_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_questions\n",
    "del tokenized_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# будем брать одну десятую датасета, иначе памяти не хватит\n",
    "with open('questions', 'rb') as f:\n",
    "    questions = pickle.load(f)\n",
    "questions = questions[:int(len(questions)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers', 'rb') as f:\n",
    "    answers = pickle.load(f)\n",
    "answers = answers[:int(len(answers)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776713 776713\n"
     ]
    }
   ],
   "source": [
    "print(len(questions), len(answers))\n",
    "assert len(questions) == len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          14961        4826        4351         575        5783        9243\r\n",
      "Swap:         16134         934       15200\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_INDEX = 0\n",
    "EOS_INDEX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceBucketingData(torch.utils.data.Dataset):\n",
    "    \"\"\"по сути то же, что в условии, только другие сиквенсы\"\"\"\n",
    "    def __init__(self, questions, answers, max_len, pad_index=PAD_INDEX, eos_index=EOS_INDEX):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        if len(questions) != len(answers):\n",
    "            raise ValueError('Вопросы и ответы должны быть одной длины')\n",
    "        self.max_len = max_len\n",
    "        self.pad_index = pad_index\n",
    "        self.eos_index = eos_index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def _prepare_sample(self, sequence_q, sequence_a, max_len_q, max_len_a):\n",
    "        sequence_q = sequence_q[:max_len_q]\n",
    "        sequence_a = sequence_a[:max_len_a]\n",
    "        x = sequence_q\n",
    "        y = sequence_a\n",
    "        pads_x = [self.pad_index] * (max_len_q - len(x))\n",
    "        pads_y = [self.pad_index] * (max_len_a - len(y))\n",
    "        x += pads_x\n",
    "        y += pads_y\n",
    "        return x, y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_q = self.questions[index]\n",
    "        batch_a = self.answers[index]\n",
    "        max_len_q = min([\n",
    "            self.max_len,\n",
    "            max(map(len, batch_q)),\n",
    "        ])\n",
    "        max_len_a = min([\n",
    "            self.max_len,\n",
    "            max(map(len, batch_a)),\n",
    "        ])\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for sample_q, sample_a in zip(batch_q, batch_a):\n",
    "            x, y = self._prepare_sample(sample_q, sample_a, self.max_len, self.max_len)\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "        batch_x = torch.tensor(batch_x).long().to(DEVICE)\n",
    "        batch_y = torch.tensor(batch_y).long().to(DEVICE)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = sorted(questions, key=len)\n",
    "answers = sorted(answers, key=len)\n",
    "\n",
    "\n",
    "# сделаем батч побольше\n",
    "BATCH_SIZE = 256\n",
    "MAX_LEN = 32\n",
    "\n",
    "batches_q = []\n",
    "batches_a = []\n",
    "\n",
    "for i_batch in range(math.ceil(len(questions) / BATCH_SIZE)):\n",
    "    q = questions[i_batch*BATCH_SIZE:(i_batch+1)*BATCH_SIZE]\n",
    "    a = answers[i_batch*BATCH_SIZE:(i_batch+1)*BATCH_SIZE]\n",
    "    if len(q) != BATCH_SIZE or len(a) != BATCH_SIZE:\n",
    "        continue\n",
    "    batches_q.append(questions[i_batch*BATCH_SIZE:(i_batch+1)*BATCH_SIZE])\n",
    "    batches_a.append(answers[i_batch*BATCH_SIZE:(i_batch+1)*BATCH_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# у нас же нет гарантии, что количество вопросов делится на батч-сайз\n",
    "# мы лишнее убрали условием сверху, надо убедиться\n",
    "all(\n",
    "    map(lambda b: True if len(b) == BATCH_SIZE else False, batches_q)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_start_index = int(len(batches_q) * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = SequenceBucketingData(\n",
    "    questions=batches_q[:-validation_start_index],\n",
    "    answers=batches_a[:-validation_start_index],\n",
    "    max_len=MAX_LEN)\n",
    "test_seq = SequenceBucketingData(\n",
    "    questions=batches_q[-validation_start_index:],\n",
    "    answers=batches_a[-validation_start_index:],\n",
    "    max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_seq, batch_size=BATCH_SIZE)\n",
    "validation_loader = torch.utils.data.DataLoader(test_seq, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# это специальный дропаут для реккуретных сетей\n",
    "# хорошо это объясняется здесь: https://youtu.be/WLaAIYQHHMU?t=1093\n",
    "\n",
    "class SpatialDropout(torch.nn.Dropout2d):\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# простой вариант из доков\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, inp, hidden):\n",
    "        embedded = self.embedding(inp).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тоже из доков\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inp, hidden):\n",
    "        output = self.embedding(inp).view(1, 1, -1)\n",
    "        output = torch.functional.F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(VOCAB_SIZE, 400).to(DEVICE)\n",
    "decoder = Decoder(400, VOCAB_SIZE).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пытаюсь понять, сделано тоже на основе доков\n",
    "\n",
    "def train(encoder, decoder, inp, target,\n",
    "          encoder_criterion, decoder_criterion,\n",
    "          encoder_optimizer, decoder_optimizer, max_len=MAX_LEN):\n",
    "    loss = 0\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    hidden = encoder.initHidden()\n",
    "    encoder_output, hidden = encoder(inp, hidden)\n",
    "    decoder_output, decoder_hidden = decoder(encoder_input, hidden)\n",
    "    \n",
    "    loss += criterion(decoder_output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(encoder, decoder, inp, target,\n",
    "             encoder_criterion, decoder_criterion,\n",
    "             encoder_optimizer, decoder_optimizer, max_len=MAX_LEN):\n",
    "    loss = 0\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    hidden = encoder.initHidden()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_output, hidden = encoder(inp, hidden)\n",
    "        decoder_output, decoder_hidden = decoder(encoder_input, hidden)\n",
    "    \n",
    "    loss += criterion(decoder_output, target)\n",
    "\n",
    "    return loss.item() / target.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_INDEX)\n",
    "decoder_criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_INDEX)\n",
    "encoder_optimizer = torch.optim.Adam(params=encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(params=decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_loader, test_loader, epochs=10, last_n_losses=500):\n",
    "    losses = []\n",
    "    best_validation_loss = 1e+6\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
