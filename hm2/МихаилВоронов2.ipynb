{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Михаил Воронов_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Код, примерно скопированный из задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-14 13:51:45--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
      "Распознаётся dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)… 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Подключение к dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 681808098 (650M) [application/zip]\n",
      "Сохранение в: «wiki-news-300d-1M.vec.zip.1»\n",
      "\n",
      "ki-news-300d-1M.vec   3%[                    ]  19,94M  6,79MB/s               ^C\n"
     ]
    }
   ],
   "source": [
    "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-14 13:52:26--  https://raw.githubusercontent.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/master/Week%203/data.py\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 151.101.36.133\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|151.101.36.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 10563 (10K) [text/plain]\n",
      "Сохранение в: «data.py»\n",
      "\n",
      "data.py             100%[===================>]  10,32K  --.-KB/s    за 0s      \n",
      "\n",
      "2020-11-14 13:52:26 (62,7 MB/s) - «data.py» сохранён [10563/10563]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget \"https://raw.githubusercontent.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/master/Week 3/data.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для прошлого задания нужна была специальная версия торча, так как я не создавал окружения,\n",
    "теперь надо вернуть нормальную для моей куды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.7.0+cu101\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (735.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 735.3MB 26kB/s s eta 0:00:01    16% |█████▍                          | 124.5MB 104.8MB/s eta 0:00:06�█                         | 161.2MB 143.1MB/s eta 0:00:05��████████▌                    | 263.9MB 56.8MB/s eta 0:00:09    56% |██████████████████              | 414.0MB 27.0MB/s eta 0:00:12    60% |███████████████████▍            | 446.0MB 55.1MB/s eta 0:00:06██████            | 461.2MB 83.2MB/s eta 0:00:04��████████████████▏        | 533.5MB 48.9MB/s eta 0:00:05MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting torchvision==0.8.1+cu101\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.7MB 2.2MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/75/5ce994c76cf7b53ff8c577d7a8221fa0c9dfe9e34c0536c6eaf3e466788a/torchaudio-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (7.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.6MB 2.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting typing-extensions (from torch==1.7.0+cu101)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Requirement already satisfied: future in /home/misha/.local/lib/python3.7/site-packages (from torch==1.7.0+cu101) (0.17.1)\n",
      "Requirement already satisfied: numpy in /home/misha/.local/lib/python3.7/site-packages (from torch==1.7.0+cu101) (1.16.4)\n",
      "Collecting dataclasses (from torch==1.7.0+cu101)\n",
      "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/lib/python3/dist-packages (from torchvision==0.8.1+cu101) (5.4.1)\n",
      "Installing collected packages: typing-extensions, dataclasses, torch, torchvision, torchaudio\n",
      "  Found existing installation: torch 1.6.0+cpu\n",
      "    Uninstalling torch-1.6.0+cpu:\n",
      "      Successfully uninstalled torch-1.6.0+cpu\n",
      "  Found existing installation: torchvision 0.7.0+cpu\n",
      "    Uninstalling torchvision-0.7.0+cpu:\n",
      "      Successfully uninstalled torchvision-0.7.0+cpu\n",
      "Successfully installed dataclasses-0.6 torch-1.7.0+cu101 torchaudio-0.7.0 torchvision-0.8.1+cu101 typing-extensions-3.7.4.3\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.3b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install --user torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from data import Downloader, Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к данным\n",
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = Downloader(data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloader.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser(data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading: 100%|██████████| 38/38 [01:55<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "unlabeled, train, valid = parser.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.category.unique().tolist()) == set(valid.category.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories = set(train.category.unique().tolist() + valid.category.unique().tolist())\n",
    "category2index = {category: index for index, category in enumerate(unique_categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = train.category.map(category2index)\n",
    "valid['target'] = valid.category.map(category2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовим данные\n",
    "train_x = list(train.question)\n",
    "train_y = list(train.target)\n",
    "\n",
    "valid_x = list(valid.question)\n",
    "valid_y = list(valid.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(zip_path, filename, pad_token='PAD', max_words=100_000, verbose=True):\n",
    "    \n",
    "    vocab = dict()\n",
    "    embeddings = list()\n",
    "\n",
    "    with zipfile.ZipFile(zip_path) as zipped_file:\n",
    "        with zipped_file.open(filename) as file_object:\n",
    "\n",
    "            vocab_size, embedding_dim = file_object.readline().decode('utf-8').strip().split()\n",
    "\n",
    "            vocab_size = int(vocab_size)\n",
    "            embedding_dim = int(embedding_dim)\n",
    "            \n",
    "            # в файле 1 000 000 слов с векторами, давайте ограничим для простоты этот словарь\n",
    "            max_words = vocab_size if max_words <= 0 else max_words\n",
    "            \n",
    "            # добавим пад токен и эмбеддинг в нашу матрицу эмбеддингов и словарь\n",
    "            vocab[pad_token] = len(vocab)\n",
    "            embeddings.append(np.zeros(embedding_dim))\n",
    "\n",
    "            progress_bar = tqdm(total=max_words, disable=not verbose)\n",
    "\n",
    "            for line in file_object:\n",
    "                parts = line.decode('utf-8').strip().split()\n",
    "\n",
    "                token = ' '.join(parts[:-embedding_dim]).lower()\n",
    "                \n",
    "                if token in vocab:\n",
    "                    continue\n",
    "                \n",
    "                word_vector = np.array(list(map(float, parts[-embedding_dim:])))\n",
    "\n",
    "                vocab[token] = len(vocab)\n",
    "                embeddings.append(word_vector)\n",
    "\n",
    "                progress_bar.update()\n",
    "                \n",
    "                if len(vocab) == max_words:\n",
    "                    break\n",
    "\n",
    "            progress_bar.close()\n",
    "\n",
    "    embeddings = np.stack(embeddings)\n",
    "    \n",
    "    return vocab, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 99999/100000 [00:08<00:00, 11294.14it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab, embeddings = load_embeddings(\n",
    "    './wiki-news-300d-1M.vec.zip',\n",
    "    'wiki-news-300d-1M.vec',\n",
    "    max_words=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2token = {index: token for token, index in vocab.items()}\n",
    "emb_norms = np.linalg.norm(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest_neighbors(word, embeddings, emb_norms, vocab, index2token, k=5):\n",
    "    \n",
    "    if word not in vocab:\n",
    "        print('Not in vocab')\n",
    "        return\n",
    "    \n",
    "    word_index = vocab[word]\n",
    "\n",
    "    word_vector = embeddings[word_index]\n",
    "    word_vector = np.expand_dims(word_vector, 0)\n",
    "\n",
    "    scores = (word_vector @ embeddings.T)[0]\n",
    "    \n",
    "    # переводим в косинусы, поделив на нормы векторов\n",
    "    # эпсилон 1e-6 для того, чтобы не делить на 0\n",
    "    scores = scores / (emb_norms + 1e-6) / emb_norms[word_index]\n",
    "    \n",
    "    # 1:k+1 потому что первый вариант это само слово\n",
    "    for idx in scores.argsort()[::-1][1:k+1]:\n",
    "        print(f'Слово {index2token[idx]} близко на {scores[idx]:.2f} к слову {word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово maria близко на 0.73 к слову anna\n",
      "Слово emma близко на 0.66 к слову anna\n",
      "Слово kristina близко на 0.65 к слову anna\n",
      "Слово laura близко на 0.65 к слову anna\n",
      "Слово emily близко на 0.65 к слову anna\n"
     ]
    }
   ],
   "source": [
    "get_k_nearest_neighbors('anna', embeddings, emb_norms, vocab, index2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, texts, targets, vocab, pad_index=0, max_length=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.pad_index = pad_index\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def tokenization(self, text):\n",
    "        \n",
    "        tokens = wordpunct_tokenize(text)\n",
    "        \n",
    "        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n",
    "        \n",
    "        return token_indices\n",
    "    \n",
    "    def padding(self, tokenized_text):\n",
    "        \n",
    "        tokenized_text = tokenized_text[:self.max_length]\n",
    "        \n",
    "        tokenized_text += [self.pad_index] * (self.max_length - len(tokenized_text))\n",
    "        \n",
    "        return tokenized_text\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text = self.texts[index]        \n",
    "        target = self.targets[index]\n",
    "        \n",
    "        tokenized_text = self.tokenization(text)\n",
    "        tokenized_text = self.padding(tokenized_text)\n",
    "        \n",
    "        tokenized_text = torch.tensor(tokenized_text)\n",
    "        \n",
    "        return tokenized_text, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how',\n",
       " 'many',\n",
       " 'inches',\n",
       " 'does',\n",
       " 'this',\n",
       " 'lift',\n",
       " 'the',\n",
       " 'hitch',\n",
       " '-',\n",
       " 'from',\n",
       " 'top',\n",
       " 'of',\n",
       " 'hitch',\n",
       " 'bar',\n",
       " 'to',\n",
       " 'top',\n",
       " 'of',\n",
       " 'platform',\n",
       " '?',\n",
       " 'PAD']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index2token[idx.item()] for idx in x][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)\n",
    "valid_dataset = TextClassificationDataset(texts=valid_x, targets=valid_y, vocab=vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаю на видюхе\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            emdeddings,\n",
    "            nclasses: int,\n",
    "            lstm_size: int):\n",
    "        super().__init__()\n",
    "        self._embeddings_layer = torch.nn.Embedding.from_pretrained(\n",
    "            torch.tensor(embeddings).float().to(DEVICE), padding_idx=0)\n",
    "        self._embeddings_dim = embeddings.shape[-1]\n",
    "        self._lstm = torch.nn.LSTM(\n",
    "            self._embeddings_dim,\n",
    "            lstm_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self._classification_layer = torch.nn.Linear(280, nclasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._embeddings_layer(x)\n",
    "        x, _ = self._lstm(x)\n",
    "        x = F.relu(x)\n",
    "        z = self._classification_layer(x)\n",
    "        return self._classification_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-59e0f128d44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-61c60879d5eb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classification_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classification_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "epochs = 6\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "model = LstmModel(embeddings, 8, 200).to(DEVICE)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for x, y in train_loader:\n",
    "        x = x.view(x.shape[0], -1).to(DEVICE)\n",
    "        pred = model.forward(x)\n",
    "        train_loss = criterion(pred, y.to(DEVICE))\n",
    "        train_loss.backward()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    for x, y in valid_loader:\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "        test_loss = criterion(pred, y.to(DEVICE))\n",
    "    test_losses.append(test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 12))\n",
    "plt.plot(range(epochs), train_losses)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-e2ab3ea573f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[6][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
